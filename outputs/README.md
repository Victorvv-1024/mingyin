# Outputs Directory

This directory contains all outputs generated by the MingYin sales forecasting pipeline, organized by experiment.

## Directory Structure

```
outputs/
└── {experiment_name}/              # Timestamped experiment folder (e.g., 20250616_120000)
    ├── vanilla_models/             # Vanilla embedding model files
    ├── enhanced_models/            # Enhanced embedding model files  
    ├── predictions/                # Model predictions and performance metrics
    ├── reports/                    # Experiment reports and metadata
    └── feature_engineering/        # Feature engineering outputs and statistics
```

## Experiment Organization

Each experiment run creates a new folder with timestamp: `YYYYMMDD_HHMMSS`

Example: `outputs/20250616_120000/`

## Generated Files by Subfolder

### `vanilla_models/`
- `vanilla_embedding_model_fold_*.keras` - Vanilla model checkpoints for each validation fold
- `vanilla_model_architecture.json` - Model configuration
- `vanilla_training_history.json` - Training metrics and loss curves
- `vanilla_best_model.keras` - Best performing vanilla model

### `enhanced_models/`
- `enhanced_embedding_model_fold_*.keras` - Enhanced model checkpoints for each validation fold
- `enhanced_model_architecture.json` - Model configuration
- `enhanced_training_history.json` - Training metrics and loss curves
- `enhanced_best_model.keras` - Best performing enhanced model

### `predictions/`
- `vanilla_predictions_fold_*.csv` - Vanilla model predictions per fold
- `enhanced_predictions_fold_*.csv` - Enhanced model predictions per fold
- `vanilla_performance_metrics.txt` - Vanilla model MAPE, MAE, RMSE scores
- `enhanced_performance_metrics.txt` - Enhanced model MAPE, MAE, RMSE scores
- `model_comparison_summary.csv` - Vanilla vs Enhanced model comparison
- `phase3_2023_evaluation.csv` - 2023 test results (if Phase 3 run)

### `reports/`
- `experiment_report.txt` - Detailed experiment summary
- `experiment_metadata.json` - Configuration and hyperparameters
- `phase2_validation_results/` - Rolling validation detailed results
- `phase3_evaluation_results/` - 2023 test results and business insights
- `model_comparison_report.txt` - Comprehensive model comparison analysis

### `feature_engineering/`
- `feature_importance_vanilla.csv` - Vanilla model feature importance rankings
- `feature_importance_enhanced.csv` - Enhanced model feature importance rankings
- `feature_statistics.json` - Feature engineering statistics and metadata
- `correlation_analysis.csv` - Feature correlation matrices
- `feature_engineering_log.txt` - Processing log and statistics

## Model Performance Benchmarks

- **Vanilla Model**: ~18-22% MAPE (baseline comparison)
- **Enhanced Model**: ~14-18% MAPE (production deployment)

## Usage Examples

### Single Experiment
```bash
python run_complete_pipeline.py --model-type enhanced
# Creates: outputs/20250616_120000/enhanced_models/
```

### Model Comparison
```bash
python run_complete_pipeline.py --model-type both
# Creates: outputs/20250616_120000/{vanilla_models,enhanced_models}/
```

### Full Pipeline with 2023 Evaluation
```bash
python run_complete_pipeline.py --model-type both --run-phase3
# Creates: outputs/20250616_120000/ with all subfolders
```

## Note

Model files (.keras) are not included in git due to size constraints (>100MB each). Run the training pipeline to generate models locally in the experiment-specific folders. 